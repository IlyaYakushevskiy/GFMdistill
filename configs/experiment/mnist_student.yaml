# @package _global_

###reduce num layers /2 and change loss
defaults:
  - _self_
  - /dataset: mnist
  - /encoder: cnn_teacher
  - /decoder: cnn_teacher
  - /preprocessing: mnist_preprocessor
  - /criterion: cross_entropy
  - /task: linear_classification
  

# --- Specific value overrides for this experiment ---
train: true 
finetune: false
batch_size: 64
test_batch_size: 64
task: 
  trainer:
    n_epochs: 50



